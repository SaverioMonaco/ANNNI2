{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../tensor_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "import os\n",
    "import pennylane as qml\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mpsANNNI:\n",
    "    def __init__(self, folder : str = '../tensor_data/'):\n",
    "        self.path = folder\n",
    "\n",
    "        # Check if folder exists\n",
    "        try: \n",
    "            files_all = np.array(os.listdir(folder))\n",
    "            self.files_shape = files_all[np.char.startswith(files_all,'shapes_sites')]\n",
    "            self.files_tens  = files_all[np.char.startswith(files_all,'tensor_sites')]\n",
    "        except:\n",
    "            raise TypeError(f'Folder {folder} not found')\n",
    "        \n",
    "        def get_info(file_string : str) -> Tuple[int, float, float]:\n",
    "            \"\"\"\n",
    "            1. Split big string into array of string\n",
    "            'shapes_sites_ANNNI_L_{L}_h_{h}_kappa_{k}'\n",
    "                into\n",
    "            ['shapes', 'sites', 'ANNNI', 'L', '{L}','h', '{h}', 'kappa', '{k}']\n",
    "              0         1        2        3    4^    5    6^     7        8^\n",
    "            2. Take the element 4, 6 and 8 \n",
    "            \"\"\"\n",
    "            split_str = file_string.split('_')\n",
    "\n",
    "            # return respectively:\n",
    "            # L, h, k, precision on h, precision on k\n",
    "            return int(split_str[4]), float(split_str[6]), float(split_str[8]), len(split_str[6].split('.')[1]), len(split_str[8].split('.')[1])\n",
    "        \n",
    "        # Check if files are okay\n",
    "        Ls_shape, hs_shape, ks_shape, hs_shape_prec, ks_shape_prec = [], [], [], [], []\n",
    "        Ls_tens,  hs_tens,  ks_tens,  hs_tens_prec,  ks_tens_prec  = [], [], [], [], []\n",
    "        for file in self.files_shape:\n",
    "            L, h, k, hprec, kprec = get_info(file)\n",
    "            Ls_shape.append(L)\n",
    "            hs_shape.append(h)\n",
    "            ks_shape.append(k)\n",
    "            hs_shape_prec.append(hprec)\n",
    "            ks_shape_prec.append(kprec)\n",
    "        for file in self.files_tens:\n",
    "            L, h, k, hprec, kprec = get_info(file)\n",
    "            Ls_tens.append(L)\n",
    "            hs_tens.append(h)\n",
    "            ks_tens.append(k)\n",
    "            hs_tens_prec.append(hprec)\n",
    "            ks_tens_prec.append(kprec)\n",
    "\n",
    "        # Check on L\n",
    "        if len(np.unique(Ls_shape)) > 1 or len(np.unique(Ls_tens)) > 1:\n",
    "            raise ValueError(f'L has multiple values')\n",
    "        elif Ls_shape[0] != Ls_tens[0]:\n",
    "            raise ValueError(f'L has inconsistent values')\n",
    "        # otherwise L is okay:\n",
    "        self.L = Ls_shape[0]\n",
    "\n",
    "        # Check on h and k\n",
    "        #  None for now\n",
    "        self.hs = np.unique(hs_shape)\n",
    "        self.ks = np.unique(ks_shape)\n",
    "\n",
    "        # Check on precisions\n",
    "        if len(np.unique(hs_shape_prec + hs_tens_prec)) > 1 or len(np.unique(ks_shape_prec + ks_tens_prec)) > 1: \n",
    "            raise ValueError('Inconsistent precisions in files')\n",
    "        self.h_prec = hs_shape_prec[0]\n",
    "        self.k_prec = ks_shape_prec[0]\n",
    "\n",
    "        # Format of the file names:\n",
    "        # shape_file  : shape_sites_ANNNI_L_{N}_h_{h}_kappa_{k}\n",
    "        self.shape_str  = lambda h, k : folder+f'shapes_sites_ANNNI_L_{self.L}_h_{h:.{self.h_prec}f}_kappa_{k:.{self.k_prec}f}'\n",
    "        # tensor_file : shape_sites_ANNNI_L_{N}_h_{h}_kappa_{k}\n",
    "        self.tensor_str = lambda h, k : folder+f'tensor_sites_ANNNI_L_{self.L}_h_{h:.{self.h_prec}f}_kappa_{k:.{self.k_prec}f}'\n",
    "\n",
    "    def get_H(self, h, k):\n",
    "        \"\"\"\n",
    "        Set up Hamiltonian\n",
    "        \"\"\"\n",
    "\n",
    "        # Interaction of spins with magnetic field\n",
    "        H = - h * qml.PauliZ(0)\n",
    "        for i in range(1, self.L):\n",
    "            H = H - h * qml.PauliZ(i)\n",
    "\n",
    "        # Interaction between spins (neighbouring):\n",
    "        for i in range(0, self.L - 1):\n",
    "            H = H + (-1) * (qml.PauliX(i) @ qml.PauliX(i + 1))\n",
    "\n",
    "        # Interaction between spins (next-neighbouring):\n",
    "        for i in range(0, self.L - 2):\n",
    "            H = H + (-1) * k * (qml.PauliX(i) @ qml.PauliX(i + 2))\n",
    "\n",
    "        return H       \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps = mpsANNNI() # load the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all the information obtained from the folder:\n",
      " L = 12\n",
      "\n",
      " hs = [0.   0.1  0.11 0.2  0.21 0.3  0.32 0.4  0.42 0.5  0.53 0.6  0.63 0.7\n",
      " 0.74 0.8  0.84 0.9  0.95 1.   1.05 1.1  1.16 1.2  1.26 1.3  1.37 1.4\n",
      " 1.47 1.58 1.68 1.79 1.89 2.  ]\n",
      " hs (precision) = 2\n",
      "\n",
      " ks = [0.   0.05 0.1  0.11 0.15 0.16 0.2  0.21 0.25 0.26 0.3  0.32 0.35 0.37\n",
      " 0.4  0.42 0.45 0.47 0.5  0.53 0.55 0.58 0.6  0.63 0.65 0.68 0.7  0.74\n",
      " 0.75 0.79 0.8  0.84 0.85 0.89 0.9  0.95 1.  ]\n",
      " ks (precision) = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are all the information obtained from the folder:\")\n",
    "print(f' L = {mps.L}\\n\\n hs = {mps.hs:}\\n hs (precision) = {mps.h_prec}\\n\\n ks = {mps.ks}\\n ks (precision) = {mps.k_prec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE:\n",
      " [-0.70710678  0.70710678 -0.70710678  0.70710678 -0.70710678  0.70710678\n",
      " -0.70710678  0.70710678 -0.70710678  0.70710678  0.70710678 -0.70710678\n",
      " -0.70710678  0.70710678  0.70710678 -0.70710678  0.70710678 -0.70710678\n",
      " -0.70710678  0.70710678 -0.70710678  0.70710678 -0.70710678  0.70710678]\n",
      "\n",
      "TENS:\n",
      " [[1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [1. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# I can also easily load the files\n",
    "print(f'SHAPE:\\n {np.loadtxt(mps.tensor_str(0,0))}\\n')\n",
    "print(f'TENS:\\n {np.loadtxt(mps.shape_str(0,0))}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
